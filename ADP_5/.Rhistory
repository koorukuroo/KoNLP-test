data(iris)
head(iris)
newRow<-data.frame(Sepal.Length=3.0, Sepal.Width=3.2, Petal.Length=1.6, Petal.Width=0.3, Species= "newsetosa" )
iris<-rbind(iris,newRow)
dim(iris)
newcol=1:151
cbind(iris,newcol)
subset(iris,select=Species,subset=(Petal.Length>1.7))
subset(iris,select=c(Sepal.Length,Petal.Length,Species),subset=c(Sepal.Width==3.0 & Petal.Width==0.2))
iris
head(with(iris,Species))
name<-c("Moe","Larry","Curly","Harry")
year.born<-c(1887,1902,1903,1964)
born<-data.frame(name,year.born,place.born)
born
name<-c("Curly","Moe","Larry")
place.born<-c("BensonHurst", "Philadelphia", "Brooklyn", "Moscow")
name<-c("Moe","Larry","Curly","Harry")
year.born<-c(1887,1902,1903,1964)
place.born<-c("BensonHurst", "Philadelphia", "Brooklyn", "Moscow")
born<-data.frame(name,year.born,place.born)
born
name<-c("Curly","Moe","Larry")
year.died<-c(1952,1975,1975)
died<-data.frame(name,year.died)
died
merge(born,died,by="name")
as.numeric("3.14")
as.integer(3.14)
as.numeric("foo")
as.character(101)
as.numeric(FALSE)
as.numeric(TRUE)
as.data.frame(x)  # dataframe????��?? ??ȯ
as.list(x)  #list????��?? ??ȯ
as.matrix(x)  #matrix ????��?? ??ȯ
as.vector(x)  #vector ????��?? ??ȯ
as.factor(x) #factor ????��?? ??ȯ
paste("Everybody","loves","cats.")
paste("Everybody","loves","cats.",sep="-")
paste("Everybody","loves","cats.",sep="")
substr("BigDataAnalysis",1,4)
ss<-c("Moe","Larry","Curly")
substr(ss,1,3)
install.packages("ggplot2")
install.packages("ggplot2")
install.packages("ggplot2")
install.packages("ggplot2")
install.packages("ggplot2")
library(ggplot2)
data(movies)
grep("Summer",movies$title)
Sys.Date()
as.Date("2013-08-13")
as.Date("08/13/2013")
as.Date("08/13/2013",format="%m/%d/%Y")
as.Date("08/13/2013",format="%m/%d/%Y")
format(Sys.Date())
as.character(Sys.Date())
format(Sys.Date(),format="%m/%d/%Y")
format(Sys.Date(),'%a')
format(Sys.Date(),'%b')
format(Sys.Date(),'%B')
format(Sys.Date(),'%d')
format(Sys.Date(),'%m')
format(Sys.Date(),'%y')
format(Sys.Date(),'%Y')
format(Sys.Date(),'%Y')
data(iris)
mydata<-na.omit(iris[,-5])
mydata<-scale(mydata)
wss<-0
for(i in 1:15)wss[i]<-sum(kmeans(mydata,centers=i)$withinss)
plot(1:15,wss,type="b",xlab="Number of Clusters",ylab="Within group sum of squares")
data(iris)
newiris<-iris
newiris$Species<-NULL
kc<-kmeans(newiris,3)
kc
table(iris$Species,kc$cluster)
plot(newiris[c("Sepal.Length","Sepal.Width")],col=kc$cluster)
points(kc$centers[,c("Sepal.Length","Sepal.Width")],col=1:3,pch=8,cex=2)
kc4<-kmeans(newiris,4)
table(iris$Species,kc4$cluster)
install.packages("party")
library(party)
summary(iris)
data(iris)
ind<-sample(2,nrow(iris),replace=TRUE,prob=c(0.7,0.3))
#학습데이터와 테스트데이터 생성
ind
#데이터가 1번 학습데이터와 2번 테스트 데이터로 나뉜걸 확인
trainData<-iris[ind==1,]
#70%가 할당되어있는 1번 학습데이터로 모델화
testData<-iris[ind==2,]
#30%가 할당되어있는 2번 테스트데이터로 모델화한것을 적용
myFormula<-Species~Sepal.Length+Sepal.Width+Petal.Length+Petal.Width
#Sepal.Length,Sepal.Width,Petal.Length,Petal.Width에 따른Species를 알고자 할때
iris_ctree<-ctree(myFormula,data=trainData)
#ctree를 이용하여 학습용데이터(trainData)를 공식(myformula)에 맞게 모델을 만들어 저장
table(predict(iris_ctree),trainData$Species)
#학습용 데이터로 만든 모델 성과 확인위해 trainData와 Species간의 차이 확인
print(iris_ctree)
#나누어지는 기준 설명
plot(iris_ctree)
#그래프를 통해 보기 좋게 나누어지는 기준 설명
testPred<-predict(iris_ctree,newdata=testData)
#학습용데이터로 만든 모델이 어느정도 정확성을 나타낸다 생각하여 테스트 데이터에 적용
table(testPred,testData$Species)
#실제 값과 예측값의 정확도 분석
install.packages("arules")
install.packages("arules")
install.packages("arules")
install.packages("arules")
library(arules)
data(Epub)
Epub
summary(Epub)
Year<-strftime(as.POSIXlt(transactionInfo(Epub)[["TimeStamp"]]),"%Y")
#Epub데이터 내의 TimeStamp중 년도만 추출
#"%Y"부분에 "%a","%A","%b","%B","%c","%d","%H","%I","%j","%m","%M","%p"
#"%S","%U","%w","%W","%x","%X","%y","%z","%Z" 각각 넣어보기
table(Year)
length(Epub)
inspect(head(Epub))
as(Epub[1:5],"list")
transactionInfo(Epub[size(Epub)>30])
data(AdultUCI)
dim(AdultUCI)
AdultUCI[1:2,]
AdultUCI[["fnlwgt"]]<-NULL
AdultUCI[["education-num"]]<-NULL
summary(AdultUCI[["age"]])
cut(AdultUCI[["age"]],c(15,37,100))
AdultUCI[["age"]]<-ordered(cut(AdultUCI[["age"]],c(15,25,45,65,100)),labels=c("young","middle","senior","old"))
AdultUCI[["hours-per-week"]]<-ordered(cut(AdultUCI[["hours-per-week"]],
c(0,25,40,60,168)),labels=c("part-time","full-time","overtime","workaholic"))
AdultUCI[["capital-gain"]]<-ordered(cut(AdultUCI[["capital-gain"]],
c(-Inf,0,median(AdultUCI[[ "capital-gain"]][AdultUCI[[ "capital-gain"]]>0]),
Inf)), labels = c("None", "Low", "High"))
AdultUCI[[ "capital-loss"]] <- ordered(cut(AdultUCI[[ "capital-loss"]],
c(-Inf,0, median(AdultUCI[[ "capital-loss"]][AdultUCI[[ "capital-loss"]]>0]),
Inf)), labels = c("None", "Low", "High"))
View(AdultUCI)
Adult<-as(AdultUCI,"transactions")
Adult
summary(Adult)
itemFrequencyPlot(Adult,support=0.1,cex.names=0.8)
itemFrequencyPlot(Adult,support=0.1,cex.names=0.8)
#cex.names가 의미하는바는 무엇일까요?
rules<-apriori(Adult,parameter=list(support=0.01,confidence=0.6))
#최소 support가 0.01, confidence가 0.6인 규칙을 찾아라
rules
summary(rules)
rulesIncomeSmall<-subset(rules,subset=rhs %in% "income=small"&lift>1.2)
rulesIncomeLarge<-subset(rules,subset=rhs %in% "income=large"&lift>1.2)
#rhs=b를 구매한 고객은 어떠한 특성을 지녔는가
length(rulesIncomeSmall)
length(rulesIncomeLarge)
inspect(head(sort(rulesIncomeSmall,by="confidence"),n=3))
inspect(head(sort(rulesIncomeLarge,by="confidence"),n=3))
write(rulesIncomeSmall,file="rulesIncomeSmall.txt",sep="\t",col.names=NA)
install.packages("pmml")
library("pmml")
rules_pmml<-pmml(rulesIncomeSmall)
setwd("C:/Users/SAMSUNG/Desktop/교육/공간분석")
install.packages("ggmap")
install.packages("sqldf")
install.packages("stringr")
install.packages("stringr")
library(stringr)
library(sqldf)
require(ggmap)
load("masterdata.Rdata")
Rmast <- master
colnames(Rmast) <- tolower(colnames(Rmast))
load("korea_map.Rdata")
#kor_map ?뜲?씠?꽣 ZIPCD '-'?젣嫄?
kor_map$ZIPCD <- str_replace_all(kor_map$ZIPCD, "[[:punct:]]", "")
# crm_id?뿉 ?뵲瑜? ?쐞寃쎈룄 ?뜲?씠?꽣 ?깮?꽦#
gis <- sqldf("select a.crm_id, b.latitude, b.longitude from master a, kor_map b where a.zipcode=b.ZIPCD")
gis1 <- sqldf("select a.crm_id, a.zipcode, b.latitude, b.longitude from master a, kor_map b where a.zipcode=b.ZIPCD")
sqldf("select count(distinct zipcode) from master")
zipcode_summary <- sqldf("select zipcode, count(*) as cnt from master  group by zipcode order by cnt desc")
zipcode_gis <- sqldf("select a.zipcode, cnt, b.latitude, b.longitude from zipcode_summary a, kor_map b where a.zipcode=b.ZIPCD")
seoul.map <- get_map("Seoul, Korea", zoom=11,source="stamen",maptype="watercolor")
Seoul.Map.2012 <- ggmap(seoul.map, base_layer = ggplot(aes(x = longitude, y = latitude), data = gis), extent = "panel")
Seoul.Map.2012 + stat_density2d(aes(x = longitude, y = latitude, fill = ..level.., alpha = ..level..), data = gis, geom = "polygon", show_guide = FALSE)
data(ChickWeight)
str(ChickWeight)
h <- ggplot(ChickWeight, aes(x=Time, y=weight, colour=Diet, group=Chick))
h + geom_line()
# data Structure -> list
h <- ggplot(ChickWeight, aes(x=Time, y=weight, colour=Diet))
h + geom_line()
h + geom_point(alpha=.3) + geom_smooth(alpha=.2, size=1)
h + geom_smooth(alpha=.4, size=3)
# 6-2. Histogram
h <- ggplot(subset(ChickWeight, Time==21), aes(x=weight, colour=Diet))
h + geom_density()
ga.data <- read.csv('http://www.babelgraph.org/data/ga_edgelist.csv', header=TRUE)
g <- graph.data.frame(ga.data, directed=FALSE)
ga.data <- read.csv('http://www.babelgraph.org/data/ga_edgelist.csv', header=TRUE)
g <- graph.data.frame(ga.data, directed=FALSE)
summary(g)
install.packages("igraph")
library(igraph)
ga.data <- read.csv('http://www.babelgraph.org/data/ga_edgelist.csv', header=TRUE)
g <- graph.data.frame(ga.data, directed=FALSE)
summary(g)
g$layout <- layout.fruchterman.reingold(g)
plot(g)
# Now let?셲 make the visualization a little more interesting. First we can remove the labels for now, and then change the size of the vertex to represent the degree, or degree centrality, corresponding to the number of partners of each vertex. In the context of transmissible infections, this would indicate the number of people a person could infect or be infected by through sexual contact. This tells us about the absolute number of partners, but not much about the relative position within the network.
V(g)$label <- NA # remove labels for now
V(g)$size <- degree(g) * 2 # multiply by 2 for scale
plot(g)
# Let?셲 examine two types of centrality: closeness and betweenness. The closeness centrality is the average shortest path from one vertex to every other on the graph. A high number indicates that a vertex is quickly reachable by the majority of vertices in the graph, while a low number indicates that the vertex is far from most other vertices on the graph. We can calculate the centrality and then rescale the values to create a color scheme to visualize the relative differences. It appears there are a few vertices on the red ?쐆ot?? end of the spectrum, and a few at the ?쐁old?? end.
clo <- closeness(g) # rescale values to match the elements of a color vector
clo.score <- round( (clo - min(clo)) * length(clo) / max(clo) ) + 1
# create color vector, use rev to make red "hot"
clo.colors <- rev(heat.colors(max(clo.score)))
V(g)$color <- clo.colors[ clo.score ]
plot(g)
install.packages("ggmap")
library(stringr)
library(sqldf)
require(ggmap)
load("masterdata.Rdata")
Rmast <- master
colnames(Rmast) <- tolower(colnames(Rmast))
load("korea_map.Rdata")
kor_map$ZIPCD <- str_replace_all(kor_map$ZIPCD, "[[:punct:]]", "")
gis <- sqldf("select a.crm_id, b.latitude, b.longitude from master a, kor_map b where a.zipcode=b.ZIPCD")
gis1 <- sqldf("select a.crm_id, a.zipcode, b.latitude, b.longitude from master a, kor_map b where a.zipcode=b.ZIPCD")
library(ggmap)
mapImageData1 <- get_map(location=c(lon=126.97947, lat=37.54893),color="color",source="google",maptype="satelite",zoom=10)
mapImageData1 <- get_map(location=c(lon=126.97947, lat=37.54893),color="color",source="google",maptype="satellite",zoom=10)
ggmap(mapImageData1,extent="device",ylab="Latitude",xlab="Longitude")
mapImageData1 <- get_map(location=c(lon=126.97947, lat=37.54893),color="color",source="google",maptype="terrain",zoom=10)
ggmap(mapImageData1,extent="device",ylab="Latitude",xlab="Longitude")
ggmap(get_google(center='korea',zoom=7,maptype='roadmap),extent='device'')
ggmap(get_google(center='korea',zoom=7,maptype='roadmap),extent='device')
ggmap(get_google(center='korea',zoom=7,maptype='roadmap'),extent='device')
ggmap(get_googlemap(center='korea',zoom=7,maptype='roadmap'),extent='device')
ggmap(get_googlemap(center='korea',zoom=7,maptype='hybrid'),extent='device')
? maptype
ggmap(get_googlemap(center='korea',zoom=7,maptype='roadmap'),extent='device')
ggmap(get_googlemap(center='korea',zoom=7,maptype='hybrid'),extent='device')
eq<-read.table("eq.txt",sep="\t",header=T,stringAsFactors=F)
eq<-read.table("eq.txt",sep="\t",header=T,stringsAsFactors=F)
head(eq)
strsplit(eq$latitude," ")
unlist(strsplit(eq$latitude," "))
eq$latitude<-unlist(strsplit(eq$latitude," "))[seq(from=1,to=nrow(eq),by=2)]
eq$longitude<-unlist(strsplit(eq$longitude," "))[seq(from=1,to=nrow(eq),by=2)]
unlist(strsplit(eq$longitude," "))
eq$longitude
eq$latitude
eq$longitude<-as.double(eq$longitude)
eq$longitude
eq$latitude<-as.double(eq$latitude)
?ymd_hm
eq$date<-ymd_hm(eq$date)
??ymd_hm
install.packages("lubridate")
library(lubridate)
eq$date<-ymd_hm(eq$date)
?ymd_hm
eq$year<-substr(eq$date,1,4)
ggmap(get_googlemap(center='korea',zoom=7,maptype='terrain'),extent='device')
geom+point(aes(x=longitude,y=latitude,size=power),data=eq, alpha=0.7)
geom_point(aes(x=longitude,y=latitude,size=power),data=eq, alpha=0.7)
+geom_point(aes(x=longitude,y=latitude,size=power),data=eq, alpha=0.7)
ggmap(get_googlemap(center='korea',zoom=7,maptype='terrain'),extent='device')
geom_point(aes(x=longitude,y=latitude,size=power),data=eq, alpha=0.7)
ggmap(get_googlemap(center='korea',zoom=7,maptype='terrain'),extent='device')+geom_point(aes(x=longitude,y=latitude,size=power),data=eq, alpha=0.7)
ggmap(get_googlemap(center='korea',zoom=7,maptype='terrain'),extent='device')+geom_point(aes(x=longitude,y=latitude,size=power),data=eq, alpha=0.5)
head(eq)
install.packages("RJSONIO")
install.packages("RJSONIO")
getGeoCode <- function(gcStr){
library("RJSONIO")
gcStr<-gsub(' ','%20',gcStr) # Encode URL Parameters
# Open Connection
connectStr<-paste('http://maps.google.com/maps/api/geocode/json?sensor=false&address=',gcStr,sep="")
con <- url(connectStr)
data.json <- fromJSON(paste(readlines(con),collapse=""))
close(con)
# Flatten the received JSON
data.json <- unlist(data.json)
if (data.json["status"]=="OK") {
lat <- data.json["results.geometry.location.lat"]
lng <- data.json["results.geometry.location.lng"]
gcodes <- c(lat,lng)
names(gcodes) <- c("Lat","Lng")
return(gcodes)
}
}
geoCodes <- getGeoCode("Palo Alto, California")
library(XML)
geoCodes <- getGeoCode("Palo Alto, California")
?? readlines
library(googleVis)
geoCodes <- getGeoCode("Palo Alto, California")
library(googleVis)
geoCodes <- getGeoCode("Palo Alto, California")
getGeoCode <- function(gcStr){
library("RJSONIO")
gcStr<-gsub(' ','%20',gcStr) # Encode URL Parameters
# Open Connection
connectStr<-paste('http://maps.google.com/maps/api/geocode/json?sensor=false&address=',gcStr,sep="")
con <- url(connectStr)
data.json <- fromJSON(paste(readLines(con),collapse=""))
close(con)
# Flatten the received JSON
data.json <- unlist(data.json)
if (data.json["status"]=="OK") {
lat <- data.json["results.geometry.location.lat"]
lng <- data.json["results.geometry.location.lng"]
gcodes <- c(lat,lng)
names(gcodes) <- c("Lat","Lng")
return(gcodes)
}
}
geoCodes <- getGeoCode("Palo Alto, California")
geoCodes
geoCodes <- getGeoCode("Seoul, South Korea")
geoCodes
geoCodes <- getGeoCode("xxx, Seoul, South Korea")
geoCodes
geoCodes <- getGeoCode("Jeju, South Korea")
geoCodes
geoCodes <- getGeoCode("Jongro Tower, Seoul, South Korea")
geoCodes
geoCodes <- getGeoCode("옥수동 성동구 서울 대한민국")
geoCodes
geoCodes <- getGeoCode("금호동4가 성동구 서울 대한민국")
geoCodes
library(ggplot2)
data(iris)
names(iris)
qplot(x-Sepal.Width, y=Petal.Length, data=iris, geom="point")
qplot(x=Sepal.Width, y=Petal.Length, data=iris, geom="point")
install.packages("Lock5Data")
library(Lock5Data)
data(SleepStudy)
names(SleepStudy)
ggplot(SleepStudy, aes(x=Drinks))+geom_bar()
ggplot(SleepStudy, aes(x=Drinks))+geom_histogram(binwidth=2,aes(y=..density..))
ggplot(SleepStudy, aes(x=ClassYear,y=Drinks))+geom_boxplot()
str(SleepStudy)
ggplot(SleepStudy, aes(x=factor(ClassYear),y=Drinks))+geom_boxplot()
ggplot(SleepStudy, aes(y=factor(ClassYear),x=Drinks))+geom_boxplot()
ggplot(SleepStudy, aes(x=factor(ClassYear),y=Drinks))+geom_boxplot()
ggplot(SleepStudy, aes(x=factor(ClassYear),y=Drinks))+geom_boxplot()+coord_flip()
install.packages("d3Network")
ggplot(SleepStudy, aes(x=Drinks))+geom_density()
library(d3Network)
library(RCurl)
Source <- c("A", "A", "A", "A", "B", "B", "C", "C", "D")
Target <- c("B", "C", "D", "J", "E", "F", "G", "H", "I")
NetworkData <- data.frame(Source, Target)
ericOpenHtml <- function(filename) {
if (Sys.info()["sysname"]=="windows") {
shell.exec(filename)
} else {
system(paste("open",filename)) # mac case
}
}
d3SimpleNetwork(NetworkData, width = 400, height = 250,file="test1.html")
ericOpenHtml("test1.html")
options(repos=c(Rstudio='http://rstudio.org/_packages', getOption('repos')))
library(shiny)
runExample("01_hello")
runExample("01_hello")
setwd("~/Documents/EDU/Publish_1_ADP/ADP_5/shiny_sample")
setwd("~/Documents/EDU/Publish_1_ADP/ADP_5")
library(shiny)
setwd("./shiny_sample")
runExample("hello_shiny")
runApp("hello_shiny")
library(shiny)
setwd("./shiny_sample")
runApp("hello_shiny")
runApp("hello_shiny")
data(movies)
data(movies,package::ggplot2)
data(movies,packages::ggplot2)
data(movies,packages=ggplot2)
data(movies,packages:ggplot2)
?data
data(movies,package=ggplot2)
library(ggplot2)
data(movies,package=ggplot2)
data(movies)
names(movies)
runApp("shinyApp")
library(shiny)
setwd("./shiny_sample")
runApp("hello_shiny")
runApp("shinyApp")
runApp("shinyApp")
setwd("./shiny_sample")
runApp("hello_shiny")
library(shiny)
runApp("hello_shiny")
runApp("shinyApp")
runApp("shinyApp")
runApp("shinyApp")
setwd("../")
library(ggplot2)
data(iris)
names(iris)
qplot(x=Sepal.Width, y=Petal.Length, data=iris, geom="point")
library(Lock5Data)
data(SleepStudy)
names(SleepStudy)
ggplot(SleepStudy, aes(x=Drinks))+geom_bar()
ggplot(SleepStudy, aes(x=Drinks))+geom_histogram(binwidth=2,aes(y=..density..))
ggplot(SleepStudy, aes(x=ClassYear,y=Drinks))+geom_boxplot()
str(SleepStudy)
ggplot(SleepStudy, aes(x=factor(ClassYear),y=Drinks))+geom_boxplot()
ggplot(SleepStudy, aes(x=factor(ClassYear),y=Drinks))+geom_boxplot()+coord_flip()
ggplot(SleepStudy, aes(x=Drinks))+geom_density()
library(d3Network)
library(RCurl)
Source <- c("A", "A", "A", "A", "B", "B", "C", "C", "D")
Target <- c("B", "C", "D", "J", "E", "F", "G", "H", "I")
NetworkData <- data.frame(Source, Target)
ericOpenHtml <- function(filename) {
if (Sys.info()["sysname"]=="windows") {
shell.exec(filename)
} else {
system(paste("open",filename)) # mac case
}
}
d3SimpleNetwork(NetworkData, width = 400, height = 250,file="test1.html")
ericOpenHtml("test1.html")
library(ggmap)
library(lubridate)
mapImageData1 <- get_map(location=c(lon=126.97947, lat=37.54893),color="color",source="google",maptype="satellite",zoom=10)
ggmap(mapImageData1,extent="device",ylab="Latitude",xlab="Longitude")
mapImageData1 <- get_map(location=c(lon=126.97947, lat=37.54893),color="color",source="google",maptype="terrain",zoom=10)
ggmap(mapImageData1,extent="device",ylab="Latitude",xlab="Longitude")
ggmap(get_googlemap(center='korea',zoom=7,maptype='roadmap'),extent='device')
ggmap(get_googlemap(center='korea',zoom=7,maptype='hybrid'),extent='device')
eq<-read.table("eq.txt",sep="\t",header=T,stringsAsFactors=F)
head(eq)
eq$latitude<-unlist(strsplit(eq$latitude," "))[seq(from=1,to=nrow(eq),by=2)]
eq$latitude<-as.double(eq$latitude)
eq$longitude<-unlist(strsplit(eq$longitude," "))[seq(from=1,to=nrow(eq),by=2)]
eq$longitude<-as.double(eq$longitude)
eq$date<-ymd_hm(eq$date)
eq$year<-substr(eq$date,1,4)
head(eq)
ggmap(get_googlemap(center='korea',zoom=7,maptype='terrain'),extent='device')+geom_point(aes(x=longitude,y=latitude,size=power),data=eq, alpha=0.7)
getGeoCode <- function(gcStr){
library("RJSONIO")
gcStr<-gsub(' ','%20',gcStr) # Encode URL Parameters
# Open Connection
connectStr<-paste('http://maps.google.com/maps/api/geocode/json?sensor=false&address=',gcStr,sep="")
con <- url(connectStr)
data.json <- fromJSON(paste(readLines(con),collapse=""))
close(con)
# Flatten the received JSON
data.json <- unlist(data.json)
if (data.json["status"]=="OK") {
lat <- data.json["results.geometry.location.lat"]
lng <- data.json["results.geometry.location.lng"]
gcodes <- c(lat,lng)
names(gcodes) <- c("Lat","Lng")
return(gcodes)
}
}
geoCodes <- getGeoCode("Palo Alto, California")
geoCodes
geoCodes <- getGeoCode("Seoul, South Korea")
geoCodes
geoCodes <- getGeoCode("Jongro Tower, Seoul, South Korea")
geoCodes
geoCodes <- getGeoCode("Jeju, South Korea")
geoCodes
geoCodes <- getGeoCode("옥수동 성동구 서울 대한민국")
geoCodes
geoCodes <- getGeoCode("금호동4가 성동구 서울 대한민국")
geoCodes
library(shiny)
setwd("./shiny_sample")
runApp("hello_shiny")
runApp("shinyApp")
setwd("../")
library(ggmap)
getGeoCode <- function(gcStr){
library("RJSONIO")
gcStr<-gsub(' ','%20',gcStr) # Encode URL Parameters
# Open Connection
connectStr<-paste('http://maps.google.com/maps/api/geocode/json?sensor=false&address=',gcStr,sep="")
con <- url(connectStr)
data.json <- fromJSON(paste(readLines(con),collapse=""))
close(con)
# Flatten the received JSON
data.json <- unlist(data.json)
if (data.json["status"]=="OK") {
lat <- data.json["results.geometry.location.lat"]
lng <- data.json["results.geometry.location.lng"]
gcodes <- c(lat,lng)
names(gcodes) <- c("Lat","Lng")
return(gcodes)
}
}
geoCodes <- getGeoCode("옥수동 성동구 서울 대한민국")
geoCodes
